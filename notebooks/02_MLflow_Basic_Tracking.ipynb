{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0bab82",
   "metadata": {},
   "source": [
    "## 1. Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74861cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Masquer les warnings MLflow li√©s √† l'environnement\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Failed to resolve installed pip version.*\")\n",
    "logging.getLogger(\"mlflow.utils.environment\").setLevel(logging.ERROR)\n",
    "\n",
    "print(f\"MLflow Version: {mlflow.__version__}\")\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")  # URL du serveur MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292bd22e",
   "metadata": {},
   "source": [
    "## 2. Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb8d6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es charg√©es. Forme: (307507, 139)\n",
      "X shape: (307507, 138), y shape: (307507,)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../datas/02_preprocess/datas.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Donn√©es charg√©es. Forme: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erreur: Le fichier {DATA_PATH} n'a pas √©t√© trouv√©. V√©rifier le chemin.\")\n",
    "\n",
    "# S√©paration des features (X) et de la cible (y)\n",
    "if 'TARGET' in df.columns:\n",
    "    X = df.drop('TARGET', axis=1)\n",
    "    y = df['TARGET']\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "else:\n",
    "    print(\"Erreur: La colonne 'TARGET' n'a pas √©t√© trouv√©e. V√©rifier le nom de la colonne cible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446836c8",
   "metadata": {},
   "source": [
    "## 3. S√©paration des donn√©es en Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0790cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entra√Ænement : 246005 √©chantillons\n",
      "Taille de l'ensemble de test : 61502 √©chantillons\n",
      "Proportion de d√©parts dans y_train : 8.07%\n",
      "Proportion de d√©parts dans y_test : 8.07%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    "    )\n",
    "\n",
    "print(f\"Taille de l'ensemble d'entra√Ænement : {X_train.shape[0]} √©chantillons\")\n",
    "print(f\"Taille de l'ensemble de test : {X_test.shape[0]} √©chantillons\")\n",
    "print(f\"Proportion de d√©parts dans y_train : {y_train.mean():.2%}\")\n",
    "print(f\"Proportion de d√©parts dans y_test : {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae785d",
   "metadata": {},
   "source": [
    "## 4. Configuration MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f707627",
   "metadata": {},
   "source": [
    "# Suivi d'exp√©rimentations avec MLflow\n",
    "\n",
    "Objectifs:\n",
    "- Configurer MLflow (URI, exp√©rience).\n",
    "- Lancer un run de base et logger param√®tres/m√©triques/artefacts.\n",
    "- Comprendre la navigation dans l'UI et l'organisation des runs.\n",
    "\n",
    "Contenu:\n",
    "1. Chargement des donn√©es et split train/test.\n",
    "2. Baseline avec un mod√®le simple et m√©triques standard.\n",
    "3. Tracking MLflow:\n",
    "   - mlflow.set_experiment, start_run\n",
    "   - log_params, log_metrics, log_artifact\n",
    "4. Conseils:\n",
    "   - Nommage des runs (run_name)\n",
    "   - Utilisation de tags pour filtrer (ex: stage, data_split)\n",
    "   - Enregistrement d'un mod√®le dans le registry si pertinent\n",
    "\n",
    "Bonnes pratiques:\n",
    "- Toujours fixer un random_state pour la reproductibilit√©.\n",
    "- Logger les versions critiques (librairies, donn√©es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60436e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 15:24:57 INFO mlflow.tracking.fluent: Experiment with name 'Credit_Scoring_Baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Experiment set to: Credit_Scoring_Baseline\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"Credit_Scoring_Baseline\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"MLflow Experiment set to: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922d6e5",
   "metadata": {},
   "source": [
    "## 5. Premi√®re Exp√©rimentation MLflow avec un mod√®le de r√©gression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d30ad38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activer l'autologging pour sklearn (si d√©sir√©)\n",
    "# mlflow.sklearn.autolog() # Peut √™tre appel√© ici ou avant le start_run si on veut englober tout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf31a6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: d4d2e8d9d54f4724b3d3ffe2c559bb69\n",
      "Metrics for Logistic Regression (Run ID: d4d2e8d9d54f4724b3d3ffe2c559bb69):\n",
      "  ROC AUC: 0.74\n",
      "  F1-Score: 0.26\n",
      "  Recall: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'LogisticRegressionModel_CreditScoring'.\n",
      "2025/10/02 15:25:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LogisticRegressionModel_CreditScoring, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment termin√© et logg√© dans MLflow UI.\n",
      "üèÉ View run Logistic_Regression_Baseline_Run_1 at: http://localhost:5000/#/experiments/337906899368494804/runs/d4d2e8d9d54f4724b3d3ffe2c559bb69\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/337906899368494804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'LogisticRegressionModel_CreditScoring'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Logistic_Regression_Baseline_Run_1\") as run:\n",
    "    # R√©cup√©rer l'ID du run pour r√©f√©rence\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "\n",
    "    # Param√®tres du mod√®le\n",
    "    solver = 'lbfgs'\n",
    "    max_iter = 3000\n",
    "    C = 0.1\n",
    "    random_state = 42\n",
    "\n",
    "    # Log des param√®tres\n",
    "    mlflow.log_param(\"solver\", solver)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    mlflow.log_param(\"C\", C)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "    mlflow.log_param(\"model_type\", \"Logistic Regression\")\n",
    "\n",
    "    # Initialisation et entra√Ænement du mod√®le\n",
    "    #model = LogisticRegression(solver=solver, max_iter=max_iter, C=C, random_state=random_state, class_weight='balanced')\n",
    "    model = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=solver,\n",
    "            max_iter=max_iter,\n",
    "            C=C,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=random_state\n",
    "        ))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Pr√©dictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calcul des m√©triques\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred) # Rappel sur la classe positive (par d√©faut)\n",
    "\n",
    "    # Log des m√©triques\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"recall_score\", recall)\n",
    "\n",
    "    print(f\"Metrics for Logistic Regression (Run ID: {run_id}):\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.2f}\")\n",
    "    print(f\"  F1-Score: {f1:.2f}\")\n",
    "    print(f\"  Recall: {recall:.2f}\")\n",
    "\n",
    "    # Enregistrement du mod√®le\n",
    "    # mlflow.sklearn.log_model(model, \"logistic_regression_model\")\n",
    "    # Pour une meilleure gestion des artefacts et versioning:\n",
    "    # mlflow.log_artifact(\"02_MLflow_Basic_Tracking.ipynb\") # Enregistre le script actuel (utile pour la reproductibilit√©)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        name=\"logistic_regression_model\",\n",
    "        input_example=X_train.iloc[:5],  # petit √©chantillon d‚Äôentr√©e\n",
    "        registered_model_name=\"LogisticRegressionModel_CreditScoring\", # Enregistre le mod√®le dans le Model Registry\n",
    "        signature=infer_signature(X_train, model.predict(X_train))  # sch√©ma I/O\n",
    "    )\n",
    "\n",
    "    # Ajout de tags\n",
    "    mlflow.set_tag(\"stage\", \"baseline\")\n",
    "    mlflow.set_tag(\"data_source\", \"Home_Credit_Kaggle\")\n",
    "    mlflow.set_tag(\"author\", \"Christopher\")\n",
    "    mlflow.set_tag(\"comments\", \"Idem que Run_1 et Run_2 mais suppression des corr√©lations > 0.7 avant split.\")\n",
    "\n",
    "    print(\"Experiment termin√© et logg√© dans MLflow UI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471814c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pret_a_depenser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
