---
title: Pret A Depenser API
emoji: üí∏
colorFrom: green
colorTo: blue
sdk: docker
pinned: false
app_port: 7860
---

# API de Scoring Cr√©dit - Pr√™t √† D√©penser

Cette API expose un mod√®le de Machine Learning (LightGBM) pour pr√©dire le risque de d√©faut de cr√©dit.

## Utilisation

L'API est document√©e via Swagger UI.
Endpoint de pr√©diction : `/predict`

# Documentation du pipeline de scoring

## Structure du projet
- Donn√©es: `datas/`
- Notebooks: `notebooks/` ‚Äî exploration, tracking, comparaison mod√®les, HPO + optimisation de seuil
- Code source: `src/` ‚Äî utilitaires de mod√©lisation et fonctions m√©tier
- Suivi d'exp√©riences: `mlruns/` et `mlartifacts/`

## Modules cl√©s
- Mod√©lisation: [`src/modeling.py`](src/modeling.py)
  - [`modeling.evaluate_model`](src/modeling.py): calcule les m√©triques (incl. PR AUC)
  - [`modeling.log_light_confusion_matrix`](src/modeling.py): log de matrice de confusion
  - [`modeling.log_feature_importance`](src/modeling.py): importances des features (arbres)
  - [`modeling.custom_business_cost_scorer`](src/modeling.py): co√ªt m√©tier (FN > FP)
  - [`modeling.train_and_track_model_with_cv`](src/modeling.py): CV + tracking MLflow

## Lancer MLflow UI
Dans un terminal:
```sh
mlflow server --host 0.0.0.0 --port 5001 --backend-store-uri ./mlruns
```
Puis ouvrez: http://localhost:5001

## M√©triques et co√ªt m√©tier
- Jeu d√©s√©quilibr√©: suivre ROC AUC, PR AUC, Recall, Precision, F1.
- Co√ªt m√©tier:
  $total\_cost = FP \cdot COST\_{FP} + FN \cdot COST\_{FN}$
  Le score optimis√© est $-total\_cost$ (convention sklearn: maximisation).

## Processus global
1) Pr√©paration & feature engineering ‚Äî voir [notebooks/01_exploration_donnees.ipynb](notebooks/01_exploration_donnees.ipynb)  
2) Tracking MLflow ‚Äî voir [notebooks/02_MLflow_Basic_Tracking.ipynb](notebooks/02_MLflow_Basic_Tracking.ipynb)  
3) Comparaison multi-mod√®les ‚Äî voir [notebooks/03_Model_Comparison_and_CV.ipynb](notebooks/03_Model_Comparison_and_CV.ipynb)  
4) HPO + optimisation du seuil ‚Äî voir [notebooks/04_Hyperparameter_Tuning_and_Threshold_Optimization.ipynb](notebooks/04_Hyperparameter_Tuning_and_Threshold_Optimization.ipynb)

## Bonnes pratiques
- Fixer `random_state` pour la reproductibilit√©.
- G√©rer le d√©s√©quilibre (class_weight, is_unbalance, SMOTE).
- Logger syst√©matiquement param√®tres/m√©triques/artefacts (MLflow).
- Documenter les d√©cisions m√©tier (seuil, co√ªts).